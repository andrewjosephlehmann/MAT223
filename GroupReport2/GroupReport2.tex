% !TeX program = lualatex

\documentclass{article}
\usepackage{tikz}
\usepackage[utf8]{inputenc}
\setlength{\parindent}{0em} %indents to paragraphs
\setlength{\parskip}{1em} %lineskips after paragraph breaks
\usepackage[margin=1.0in]{geometry} %margins
\usepackage{bbm}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{enumerate}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{tikz-feynman}
\usepackage{amsmath}
\usepackage{physics}
\usetikzlibrary{calc}
\usepackage{feynmp}
\usepackage{feynmp-auto}
\usepackage{breqn}
\usepackage{graphicx}
\usepackage{mathtools}
\newcommand{\vectorproj}[2][]{\textit{proj}_{{#1}}{#2}}
\newcommand{\vect}{\mathbf}

\newenvironment{amatrix}[1]{%
	\left(\begin{array}{@{}*{#1}{c}|c@{}}
	}{%
	\end{array}\right)
}
\makeatletter
\let\@@span\span
\def\sp@n{\@@span\omit\advance\@multicnt\m@ne}
\makeatother

\renewcommand{\span}{...}
\newcommand{\galaxy}{\includegraphics[width=0.13in]{image}}


\title{MAT223: Group Report 2}
\author{A. Lehmann, W. Lee}
\date{March 3rd 2023}

\begin{document}
	\maketitle
	\textit{Group report 2 iterates upon the concepts introduced in Group Report 1. Hence it is advised to read Group Report 1 before Group Report 2. }
	\tableofcontents
\clearpage 
\section{Linear Independence and Dependence of a Set of Vectors}
\textbar{In Group Report 1, we delved into the theory of vector spaces, which we were interested in defining $\mathbb{R}^3$. As a result, we devised three linearly independent vectors, which span would represent $\mathbb{R}^3$ itself. Therefore in this matter, we are interested in the distinction between linear independence and dependence among a set of vectors. In the theory of vector spaces, one knows a set of vectors is linearly independent if no nontrivial linear combinations of vectors are equal to the zero vector. The negation of linear independence is linear dependence. We can define linear dependence as a set of vectors in which one or more vectors are linear combinations of another. 
	

To familiarize ourselves with linear dependence, we shall view a mental model that illustrates a linear-dependent set of vectors in $\mathbb{R}^2$:
}
\begin{center}
	\begin{tikzpicture}
	
	[x={(1cm,0.4cm)}, y={(8mm, -3mm)}, z={(0cm,1cm)}, line cap=round, line join=round]
	%Coordinates
	%Vectors Parallel to Plane
	%Beginning of Axis
	\coordinate (O) at (0,0);
	%Random Point
	%%	\node[outer sep = 1pt, inner sep = 1pt] (P) at (2.5,1,5.5) {};
	
	%Axis 	
	%\draw[-latex] (-3,0,0) -- (3,0,0) node[pos = 1.05] {$x$};
	%\draw[-latex] (0,-3,0) -- (0,3,0) node[pos = 1.05] {$y$};
	%%	\draw[draw=black, fill=black] (O) circle (1pt) node[below] {${O}$};
	
	%Vectors
	\draw[->, thick, red] (0,0) -- node[right] {$\vec{a}$} (2,2);
	\draw[->, thick, blue] (0,0) -- node[below] {$\vec{c}$} (5,1);
	\draw[->, thick, green] (0,0) -- node[below] {$\vec{b}$} (4,2);
	
	%	%Random Point
	%	\draw[-latex, thick] (O) -- (P) node[pos=0.45, shift={(0.1,0.3)}] {$\vb{r}$};
	%	\draw[draw=black, fill=black] (P) circle (1pt) node[above right] {$\mathrm{P}$};
	
\end{tikzpicture}
$I = \left\lbrace\vec{a}, \vec{b}, \vec{c}\right\rbrace$

\end{center}

\textbar{In this case, this set contains a redundant vector which makes this set of vectors linearly dependent. A redundant vector means the entire set can be expressed as linear combinations of other vectors. So, how does one make this set linearly independent? The answer is simple: remove one of the three vectors in this set and receive a set of linearly independent vectors. 
	
\text{Thus,}
\begin{center}
	\subsubsection{The Geometric Definition of Linearly Dependent and Independent}
	\textit{We say the vectors $\vec{v}_1, \vec{v}_2,...,\vec{v}_n$ are linearly independent if for at least one i,}
\end{center}
\begin{center}
		$\vec{v}_i \in span\lbrace \vec{v}_1, \vec{v}_2,...,\vec{v}_{i-1}, \vec{v}_{i+1},..., \vec{v}_n \rbrace
		$
\end{center}
\begin{center}
	\textit{Otherwise, they are called linearly independent.}
\end{center}

\textbar{Here are illustrations of the same vectors, now as linearly independent sets of vectors in $\mathbb{R}^2$:}

\begin{center}
	$ I = \left\lbrace \vec{a}, \vec{b}, \vec{c}\right\rbrace $
\end{center}
\begin{center}
		$A = \left\lbrace\vec{a}\right\rbrace, B =\lbrace\vec{b}\rbrace, C = \lbrace\vec{c}\rbrace \implies A\cup B\cup C = I 
	$
\end{center}
\begin{center}
	\begin{tikzpicture}
		
		[x={(1cm,0.4cm)}, y={(8mm, -3mm)}, z={(0cm,1cm)}, line cap=round, line join=round]
		%Coordinates
		%Vectors Parallel to Plane
		%Beginning of Axis
		\coordinate (O) at (0,0);
		%Random Point
		%%	\node[outer sep = 1pt, inner sep = 1pt] (P) at (2.5,1,5.5) {};
		
		%Axis 	
		%\draw[-latex] (-3,0,0) -- (3,0,0) node[pos = 1.05] {$x$};
		%\draw[-latex] (0,-3,0) -- (0,3,0) node[pos = 1.05] {$y$};
		%%	\draw[draw=black, fill=black] (O) circle (1pt) node[below] {${O}$};
		
		%Vectors
		\draw[->, thick, red] (0,0) -- node[right] {$\vec{a}$}(2,2);
		\draw[->, thick, blue] (0,0) -- node[below] {$\vec{c}$}(5,1);
		%\draw[->, thick, green] (0,0) --(4,2);
		
		%	%Random Point
		%	\draw[-latex, thick] (O) -- (P) node[pos=0.45, shift={(0.1,0.3)}] {$\vb{r}$};
		%	\draw[draw=black, fill=black] (P) circle (1pt) node[above right] {$\mathrm{P}$};
	\end{tikzpicture}
	%
	\begin{tikzpicture}
		
		[x={(1cm,0.4cm)}, y={(8mm, -3mm)}, z={(0cm,1cm)}, line cap=round, line join=round]
		%Coordinates
		%Vectors Parallel to Plane
		%Beginning of Axis
		\coordinate (O) at (0,0);
		%Random Point
		%%	\node[outer sep = 1pt, inner sep = 1pt] (P) at (2.5,1,5.5) {};
		
		%Axis 	
		%\draw[-latex] (-3,0,0) -- (3,0,0) node[pos = 1.05] {$x$};
		%\draw[-latex] (0,-3,0) -- (0,3,0) node[pos = 1.05] {$y$};
		%%	\draw[draw=black, fill=black] (O) circle (1pt) node[below] {${O}$};
		
		%Vectors
		\draw[->, thick, red] (0,0) -- node[right] {$\vec{a}$}(2,2);
		%\draw[->, thick, blue] (0,0) -- (5,1);
		\draw[->, thick, green] (0,0) -- node[below] {$\vec{b}$} (4,2);
		
		%	%Random Point
		%	\draw[-latex, thick] (O) -- (P) node[pos=0.45, shift={(0.1,0.3)}] {$\vb{r}$};
		%	\draw[draw=black, fill=black] (P) circle (1pt) node[above right] {$\mathrm{P}$};
		
	\end{tikzpicture}
	%
	\begin{tikzpicture}
	
	[x={(1cm,0.4cm)}, y={(8mm, -3mm)}, z={(0cm,1cm)}, line cap=round, line join=round]
	%Coordinates
	%Vectors Parallel to Plane
	%Beginning of Axis
	\coordinate (O) at (0,0);
	%Random Point
	%%	\node[outer sep = 1pt, inner sep = 1pt] (P) at (2.5,1,5.5) {};
	
	%Axis 	
	%\draw[-latex] (-3,0,0) -- (3,0,0) node[pos = 1.05] {$x$};
	%\draw[-latex] (0,-3,0) -- (0,3,0) node[pos = 1.05] {$y$};
	%%	\draw[draw=black, fill=black] (O) circle (1pt) node[below] {${O}$};
	
	%Vectors
	%\draw[->, thick, red] (0,0) -- (2,2);
	\draw[->, thick, blue] (0,0) -- node[below] {$\vec{c}$}(5,1);
	\draw[->, thick, green] (0,0) -- node[below] {$\vec{b}$}(4,2);
	
	%	%Random Point
	%	\draw[-latex, thick] (O) -- (P) node[pos=0.45, shift={(0.1,0.3)}] {$\vb{r}$};
	%	\draw[draw=black, fill=black] (P) circle (1pt) node[above right] {$\mathrm{P}$};
	
\end{tikzpicture}
\end{center}
\begin{center}
$I \cap$($A \cup C$) \hspace*{3cm} $I \cap $($A \cup B$) \hspace*{3cm} $I \cap $($B \cup C$)
\end{center}

\textbar{In a more mathematically rigorous approach, we may determine whether a set of vectors is linearly independent or linearly dependent. Then, we can look at the trivial and non-trivial solutions of
	\begin{center} $\alpha_{1}\vec{v}_{1} + \alpha_{2}\vec{v}_{2} + ... + \alpha_{n}\vec{v}_{n} = \vec{0}$
	\textit{,	where $\alpha_{1},\alpha_{2},...,\alpha_{n}$ are scalars.}
	\end{center}
\text{Therefore,}
	\begin{center}
		\subsubsection{Definition of Trivial Linear Combination}
		\textit{The linear combination $\alpha_{1}\vec{v}_1 + ... + \alpha_{n}\vec{v}_{n}$ is called trivial if $\alpha_{1} = ... = \alpha_{n} = 0.$ If at least one $\alpha_{i} \neq 0$, the linear combination is called non-trivial.} 
		\end{center}
The set is linearly dependent if the linear combination contains a non-zero scalar. Otherwise, if all scalars equal zero, the set of vectors is linearly independent.}
%%% continue with examples explaining as to why that is the case. %%%

\subsection{Subspaces in $\mathbb{R}^3$}
\textbar{A vector space is a collection of vectors that can be combined and multiplied by scalars in a linearly consistent manner. For instance, the set of all 3-dimensional vectors with real-number coordinates is a vector space, where their components define vector addition and scalar multiplication. Now, what is a subspace? First, we may ponder a subspace as a subset of a vector space. This subset of vectors, in turn, has properties of a vector space. In other words, a subspace is a smaller vector space contained in a larger one. 
}


\begin{center}
	\subsubsection{Definition of Subspace}
	\textit{Subspace. A non-empty set $ V \subset \mathbb{R}^n$ is called a subspace if for all $\vec{u}, \vec{v} \in V$ and all scalars k we have:} \\
	\textit{(1.)} \hspace*{0.1cm} \textit{$\vec{u}+\vec{v} \in V$; and}
\textit{(2.)} \hspace*{0.1cm} \textit{$k\vec{u} \in V$} \\
	
	\end{center}


\textbar{Subspaces are equivalent to spans, and this duality permits us to determine whether a set of vectors are linearly independent or dependent. Let's say, S = $\lbrace{\vec{v}_{1}, \vec{v}_{2}, \vec{v}_{3}\rbrace}$ be a subset of $\mathbb{R}^3$. Then, using the abovementioned methods, we may determine whether the set S is linearly independent or dependent. }
\subsubsection{Linear Independence of a Subspace}
\begin{center}
	${S = \lbrace \vec{v}_{1} ,\vec{v}_{2},\vec{v}_{3}  \rbrace \implies \alpha_{1}\vec{v}_{1} + \alpha_{2}\vec{v}_{2} + \alpha_{3}\vec{v}_{3} = \vec{0}}$
\end{center}
\textbar{To give an example. let's choose arbitrary vectors for our set $S$, that happens to be linearly independent.}
\begin{center}
	$ S = \lbrace \vec{v}_{1},\vec{v}_{2}, \vec{v}_{3} \rbrace \rightarrow \vec{v}_{1} = 
	\begin{bmatrix} 
		1 \\
		1 \\
		-2 
	\end{bmatrix} \space \space	\vec{v}_{2} = 
	\begin{bmatrix}
		1 \\ 
		-1 \\
		2
	\end{bmatrix} \space\space \vec{v}_{3} = 
	\begin{bmatrix}
		3 \\ 
		1 \\
		4
	\end{bmatrix}$
\end{center}
\begin{center}
\begin{tikzpicture}
	
	[x={(1cm,0.4cm)}, y={(8mm, -3mm)}, z={(0cm,1cm)}, line cap=round, line join=round]
	%Coordinates
	%Vectors Parallel to Plane
	%Beginning of Axis
	\coordinate (O) at (0,0,0);
	%Random Point
	\node[outer sep = 1pt, inner sep = 1pt] (P) at (2.5,1,5.5) {};
	
	%Axis 	
	\draw[-latex] (0,0,0) -- (3,0,0);
	\draw[-latex] (0,0,0) -- (0,2,0);
	\draw[-latex] (0,0,-4) -- (0,0,2.5);
	
	
	
	%linear independent vectors
	\draw[->, thick, black] (0,0,0) -- node[above] {$\vec{v}_{1}$} (1,1,-2);
	\draw[->, thick, black] (0,0,0) -- node[below, left] {$\vec{v}_{2}$} (1,-1,2);
	\draw[->, thick, black] (0,0,0) -- node[below] {$\vec{v}_{3}$} (3,1,4);
	
	%	%Random Point
	%	\draw[-latex, thick] (O) -- (P) node[pos=0.45, shift={(0.1,0.3)}] {$\vb{r}$};
	%	\draw[draw=black, fill=black] (P) circle (1pt) node[above right] {$\mathrm{P}$};
	
\end{tikzpicture}
\end{center}
\textbar{To uncover if a subspace is linearly independent, we must express the subspace as a matrix. Then employ reduced row echelon form to determine if there is a trivial solution to the linear combination of the set that composes this subspace.}

\begin{center}
	$S =  \left\lbrace\begin{bmatrix} 
		1 \\
		1 \\
		-2 
	\end{bmatrix},
	\begin{bmatrix}
		1 \\ 
		-1 \\
		2
	\end{bmatrix},
	\begin{bmatrix}
		3 \\ 
		1 \\
		4
	\end{bmatrix} \right\rbrace \rightarrow \begin{bmatrix}
	1 & 1 & 3 \\
	1 & -1 & 1 \\
	-2 & 2 & 4
	\end{bmatrix}$ 
\end{center}
\textbar{Utilizing the methods in (Group report 1 section 1.2), we find the trivial solution to linear combination of vectors. }

\begin{center}
$\begin{bmatrix}
		1 & 1 & 3 \\
		1 & -1 & 1 \\
		-2 & 2 & 4
	\end{bmatrix} R_{2} = R_{2} - R_{1} \rightarrow 
\begin{bmatrix}
	1 & 1 & 3 \\
	0 & -2 & -2 \\
	-2 & 2 & 4
	\end{bmatrix} R_{3} = R_{3} + 2R_{2} \rightarrow 
\begin{bmatrix}
	1 & 1 & 3 \\
	0 & -2 & -2 \\
	0 & 4 & 10
\end{bmatrix}$ 
\end{center}

\begin{center}
	$\begin{bmatrix}
		1 & 1 & 3 \\
		0 & -2 & -2 \\
		0 & 4 & 10
	\end{bmatrix} R_{2} = -\frac{R_{2}}{2} \rightarrow 
	\begin{bmatrix}
			1 & 1 & 3 \\
			0 & 1 & 1 \\
			0 & 4 & 10
		\end{bmatrix} R_{1} = R_{1} - R_{2} \rightarrow
	\begin{bmatrix}
		1 & 0 & 2 \\
		0 & 1 & 1 \\
		0 & 4 & 10
	\end{bmatrix} $ 
	
\end{center}

\begin{center}
$
	\begin{bmatrix}
		1 & 0 & 2 \\
		0 & 1 & 1 \\
		0 & 4 & 10
	\end{bmatrix} R_{3} = R_{3} - 4R_{2} \rightarrow
\begin{bmatrix}
	1 & 0 & 2 \\
	0 & 1 & 1 \\
	0 & 0 & 6 
	\end{bmatrix} R_{3} = \frac{R_{3}}{6} \rightarrow
\begin{bmatrix}
	1 & 0 & 2 \\
	0 & 1 & 1 \\
	0 & 0 & 1 
\end{bmatrix} $ 
	
\end{center}

\begin{center}
	$
	\begin{bmatrix}
		1 & 0 & 2 \\
		0 & 1 & 1 \\
		0 & 0 & 1
	\end{bmatrix} R_{1} = R_{1} - 2R_{3} \rightarrow
	\begin{bmatrix}
		1 & 0 & 0 \\
		0 & 1 & 1 \\
		0 & 0 & 1 
	\end{bmatrix} R_{2} = R_{2} - R_{3} \rightarrow
	\begin{bmatrix}
		1 & 0 & 0 \\
		0 & 1 & 0 \\
		0 & 0 & 1 
	\end{bmatrix} $ 
	
\end{center}
\textit{This reduced row echelon indicates that these arbitrary vectors are linearly independent. Since:}
\begin{center}
	$\alpha_{1} = \alpha_{2} = \alpha_{3} = 0$
\end{center}
\subsubsection{Linear Dependence of a Subspace}
\textbar{For an example of a subspace in $\mathbb{R}^3$, whose vectors are linearly dependent, we must choose a set of vectors that produce a non-trivial solution to the linear combination whose output produces the zero vector: }
\begin{center}
	${S = \lbrace \vec{v}_{1} ,\vec{v}_{2},\vec{v}_{3}  \rbrace \implies \alpha_{1}\vec{v}_{1} + \alpha_{2}\vec{v}_{2} + \alpha_{3}\vec{v}_{3} = \vec{0}}$
\end{center}
\textbar{Let us choose three vectors that comprise our linearly dependent subspace:}
\begin{center}
	$ S = \lbrace \vec{v}_{1},\vec{v}_{2}, \vec{v}_{3} \rbrace \rightarrow \vec{v}_{1} = 
	\begin{bmatrix} 
		1 \\
		1 \\
		1 
	\end{bmatrix} \space \space	\vec{v}_{2} = 
	\begin{bmatrix}
		1 \\ 
		-1 \\
		2
	\end{bmatrix} \space\space \vec{v}_{3} = 
	\begin{bmatrix}
		3 \\ 
		1 \\
		4
	\end{bmatrix}$
\end{center}
\begin{center}
	\begin{tikzpicture}
		
		[x={(1cm,0.4cm)}, y={(8mm, -3mm)}, z={(0cm,1cm)}, line cap=round, line join=round]
		%Coordinates
		%Vectors Parallel to Plane
		%Beginning of Axis
		\coordinate (O) at (0,0,0);
		%Random Point
		\node[outer sep = 1pt, inner sep = 1pt] (P) at (2.5,1,5.5) {};
		
		%Axis 	
		\draw[-latex] (0,0,0) -- (3,0,0);
		\draw[-latex] (0,0,0) -- (0,2,0);
		\draw[-latex] (0,0,0) -- (0,0,2.5);
		
		
		
		%linear independent vectors
		\draw[->, thick, black] (0,0,0) -- node[above] {$\vec{v}_{1}$} (1,1,1);
		\draw[->, thick, black] (0,0,0) -- node[below, left] {$\vec{v}_{2}$} (1,-1,2);
		\draw[->, thick, black] (0,0,0) -- node[below] {$\vec{v}_{3}$} (3,1,4);
		
		%	%Random Point
		%	\draw[-latex, thick] (O) -- (P) node[pos=0.45, shift={(0.1,0.3)}] {$\vb{r}$};
		%	\draw[draw=black, fill=black] (P) circle (1pt) node[above right] {$\mathrm{P}$};
		
	\end{tikzpicture}
\end{center}
\textbar{Much like linear independence, we must express the set that composes such a subspace in a matrix to find if a subspace is linearly dependent. Then utilize reduced row reduction to determine if there is a non-trivial solution. }

\begin{center}
	$S =  \left\lbrace\begin{bmatrix} 
		1 \\
		1 \\
		1 
	\end{bmatrix},
	\begin{bmatrix}
		1 \\ 
		-1 \\
		2
	\end{bmatrix},
	\begin{bmatrix}
		3 \\ 
		1 \\
		4
	\end{bmatrix} \right\rbrace \rightarrow \begin{bmatrix}
		1 & 1 & 3 \\
		1 & -1 & 1 \\
		1 & 2 & 4
	\end{bmatrix}$ 
\end{center}
\textbar{Utilizing the methods in (Group report 1 section 1.2), we find the non-trivial solution to linear combination of vectors. }
\begin{center}
	$\begin{bmatrix}
		1 & 1 & 3 \\
		1 & -1 & 1 \\ 
		1 & 2 & 4
	\end{bmatrix} R_{2} = R_{2} - R_{1} \rightarrow 
\begin{bmatrix}
	1 & 1 & 3 \\
	0 & -2 & -2 \\
	1 & 2 & 4
	\end{bmatrix} R_{3} = R_{3} - R_{1} \rightarrow 
\begin{bmatrix}
	1 & 1 & 3 \\ 
	0 & -2 & -2 \\ 
	0 & 1 & 1
\end{bmatrix}
	$
\end{center}
\begin{center}
	$ \begin{bmatrix}
		1 & 1 & 3 \\
		0 & -2 & -2 \\
		0 & 1 & 1
		\end{bmatrix} R_{2} = -\frac{R_{2}}{2} \rightarrow
	\begin{bmatrix}
		1 & 1 & 3 \\
		0 & 1 & 1 \\
		0 & 1 & 1 
	\end{bmatrix} R_{1} = R_{1} - R_{2} \rightarrow 
	\begin{bmatrix} 
		1 & 0 & 2 \\
		0 & 1 & 1 \\
		0& 1 & 1 
	\end{bmatrix} 
		$
\end{center}
\begin{center} 
$
	\begin{bmatrix}
	1 & 0 & 2 \\
	0 & 1 & 1 \\
	0 & 1 & 1 
	\end{bmatrix} R_{3} = R_{3} - R_{2} \rightarrow 
	\begin{bmatrix}
	1 & 0 & 2 \\
	0 & 1 & 1 \\
	0 & 0 & 0
	\end{bmatrix} 
$
\end{center}
\textit{This reduced row echelon indicates that these arbitrary vectors are linearly dependent due to the formation of non-trivial solution:}
\begin{center}
$ 	\alpha_{1} + 2\alpha_{3} = 0 $ \\
$
 \alpha_{2} + \alpha_{3} = 0
$
\end{center}
\subsubsection{Methods of determining if something is linearly independent or dependent}
\textbar{As a footnote, the reader may have been pondering what means would be for us to find instantly if a set of vectors is linearly dependent or linearly independent. With the starting linear combination, I recommend choosing non-trivial or trivial solutions, which implies linear independence or dependence, then derive what vectors composed the trivial or non-trivial solutions.}

\section{Projections onto Subspaces}
%\section{Give an example of a set X and a vector $\vec{v}$ in $\mathbb{R}^2$ such that projxv does not exist (i.e. make sense mathematically). Explain your thinking and use a diagram or graph.}
\textbar{A projection onto a subspace is a linear transformation that maps a vector onto a subspace, constructing the nearest vector in that subspace to the initial vector.

Thus,}
\begin{center}
\subsubsection{Definition of Projection}
\textit{Let $A\subset\mathbb{R}^n$ be a set. The projection of a vector $\vec{b}\in\mathbb{R}^n$ onto $A$, \\ written $\vectorproj[A]{\vec{b}}$, is the closest point in $A$ to $\vec{b}$.}
			
\end{center}

\textbar{To understand this concept more thoroughly, let us have a mathematical exploration of what a projection is, which may help us develop a greater understanding of this concept in linear algebra. Here we have two mathematical objects in $\mathbb{R}^2$, a vector $\vec{b}$ and a one dimentional subspace in $\mathbb{R}^2$ we denote as $A$. }

\begin{center}
	\begin{tikzpicture}
		
		[x={(1cm,0.4cm)}, y={(8mm, -3mm)}, z={(0cm,1cm)}, line cap=round, line join=round]
		%Coordinates
		%Vectors Parallel to Plane
		%Beginning of Axis
		\coordinate (O) at (0,0);
		%Random Point
		%%	\node[outer sep = 1pt, inner sep = 1pt] (P) at (2.5,1,5.5) {};
		
		%Axis 	
		\draw[-latex] (-3,0,0) -- (3,0,0) node[pos = 1.05] {$x$};
		\draw[-latex] (0,-3,0) -- (0,3,0) node[pos = 1.05] {$y$};
		%%	\draw[draw=black, fill=black] (O) circle (1pt) node[below] {${O}$};
		
		%Vectors
		\draw[-, thick, red] (-3,-1) -- node[pos = 1.05] {$A$} (3,1);
		%\draw[->, thick, blue] (0,0) -- node[below] {$\vec{c}$} (5,1);
		\draw[->, thick, blue] (0,0) -- node[pos = 1.15] {$\vec{b}$} (1,1);
		
		%	%Random Point
		%	\draw[-latex, thick] (O) -- (P) node[pos=0.45, shift={(0.1,0.3)}] {$\vb{r}$};
		%	\draw[draw=black, fill=black] (P) circle (1pt) node[above right] {$\mathrm{P}$};
		
	\end{tikzpicture}
	
\end{center}
\textbar{The closest point from $\vec{b}$ to line (A) would be considered $\vectorproj[A]{\vec{b}}$. When we draw this new line, we notice that it is normal to the subspace.}
\begin{center}
	\begin{tikzpicture}
		
	%	[x={(1cm,0.4cm)}, y={(8mm, -3mm)}, z={(0cm,1cm)}, line cap=round, line join=round]
		%Coordinates
		%Vectors Parallel to Plane
		%Beginning of Axis
		\coordinate (O) at (0,0);
		%Random Point
		%%	\node[outer sep = 1pt, inner sep = 1pt] (P) at (2.5,1,5.5) {};
		
		%Axis 	
		\draw[-latex] (-3,0,0) -- (3,0,0) node[pos = 1.05] {$x$};
		\draw[-latex] (0,-3,0) -- (0,3,0) node[pos = 1.05] {$y$};
		%%	\draw[draw=black, fill=black] (O) circle (1pt) node[below] {${O}$};
		
		%Vectors
		\draw[-, thick, red] (-3,-1) -- node[pos = 1.05] {$A$} (3,1);
		\draw[-, thick, black] (1,1) -- node[right, pos = 1.25] {$\vectorproj[A]{\vec{b}}$} (1.2,0.4);
		\draw[->, thick, blue] (0,0) -- node[pos = 1.15] {$\vec{b}$} (1,1);	

		%	%Random Point
		%	\draw[-latex, thick] (O) -- (P) node[pos=0.45, shift={(0.1,0.3)}] {$\vb{r}$};
		%	\draw[draw=black, fill=black] (P) circle (1pt) node[above right] {$\mathrm{P}$};
		
	\end{tikzpicture}
	
\end{center}
\textbar{With the illustration above, one may notice that we inserted a line in black that represents the projection of $\vec{b}$ onto set $A$. We may derive a means of calculating such a projection in this particular scenario. We can think of the line as an error between set $A$ and $\vec{b}$. Therefore let us express this error mathematically as:}
\begin{center}
	$	\vec{e} = \vec{b} - \vectorproj[A]{\vec{b}}
	$
\end{center}

\textbar{Since the projection is a point in the one-dimensional subspace, we may express it as a multiple of a direction that may span that given subspace.}

\begin{center}
	$\vectorproj[A]{\vec{b}} = \alpha \vec{a}
	$
	\textit{, where $\alpha$ is some scalar}
	
\end{center}
\textbar{Now rearrange, for the equation to be equal to zero.}

%%%%% DEFINE TRANSPOSE %%%%%
\begin{center}
$ \vec{e} = \vec{b} - \vectorproj[A]{\vec{b}}$ 
\textit{and} $\vectorproj[A]{\vec{b}} = \alpha\vec{a}$
$\implies \vec{a} \cdot \vec{e} = 0 \implies \vec{a}^\intercal\vec{e} = 0 \implies \vec{a}^\intercal(\vec{b} - \vectorproj[A]{\vec{b}}) = 0 \implies  \vec{a}^\intercal(\vec{b} - \alpha\vec{a}) = 0
$
\end{center}
\textbar{The equation equal to zero offers us a step closer to finding the value of $\alpha$, giving us the vector that provides the projection. Now rearrange this equation for $\alpha$.}
\begin{center}
	$\vec{a}^\intercal(\vec{b} - \alpha\vec{a}) = 0 \implies \alpha\vec{a}^\intercal\vec{a} - \vec{a}^\intercal\vec{b} = 0 \implies \alpha\vec{a}^\intercal\vec{a} = \vec{a}^\intercal\vec{b}$
\end{center}
\begin{center}
$ \alpha\vec{a}^\intercal\vec{a} = \vec{a}^\intercal\vec{b} \implies \frac{\alpha\vec{a}^\intercal\vec{a}}{\vec{a}^\intercal\vec{a}} = \frac{\vec{a}^\intercal\vec{b}}{\vec{a}^\intercal\vec{a}} \implies \alpha = \frac{\vec{a}^\intercal\vec{b}}{\vec{a}^\intercal\vec{a}}
$
\end{center}

\begin{center}
	\textit{Since we have an expression for projection, we find a means of calculating projection of subspaces by rearranging the expressions we have derived:}
\end{center}
\begin{center}
	$ \alpha = \frac{\vec{a}^\intercal\vec{b}}{\vec{a}^\intercal\vec{a}}$ \hspace*{1cm} $\vectorproj[A]{\vec{b}} = \alpha\vec{a}$
\end{center}
\begin{center}
	$ \vectorproj[A]{\vec{b}} = \frac{\vec{a}^\intercal\vec{b}}{\vec{a}^\intercal\vec{a}} \vec{a} \implies \vectorproj[A]{\vec{b}} =\frac{\vec{a} \cdot \vec{b}}{\vec{a} \cdot \vec{a}} \vec{a}$

\end{center}
\textbar{Now with some understanding of the mathematical machinery behind projections. How does one break a projection mathematically? Before that, I would like to look at a more intuitive argument for the functioning of projections.}

\clearpage
\subsection{Shadows}

\begin{center}
	\centering
	\includegraphics[width=0.5\linewidth]{"../../../../../../../../Desktop/Screenshot 2023-03-07 at 21.33.42 (2)"}
\end{center}
\begin{center}
	\textit{Illustration: Behaviour of path traced light in $\mathbb{R}^3$ that depicts $\vec{b}$ as a sphere and set $A$ in red as a two-dimensional subspace.}
	\label{fig:screenshot-2023-03-07-at-21}
\end{center}

\textbar{With this illustration above, we get a glimpse that the projection of a vector onto a subspace can be thought of as the shadow of the vector on the subspace. For this shadow to accurately depict the projection, we must place a light that shines uniformly orthogonal to $A$. This fact offers us insight into this particular projection, which is that it has a unique solution. The solution is unique since only one shadow is cast. 

\subsubsection{A Non-Existent Shadow}

In this duality, conceptually breaking down a projection is far more approachable. This would occur when there is no set for the object to cast its shadow. However, the concept of projection being a shadow is troublesome since whenever an object becomes an element of a two-dimensional subspace, it will no longer cast a shadow onto that subspace. The projection of such a vector is an element of a subspace onto that same subspace will reveal the vector we initially projected.
}


\begin{center}
	\centering
	\includegraphics[width=0.5\linewidth]{"../../../../../../../../Desktop/Screenshot 2023-03-07 at 22.03.05"}
	\label{fig:screenshot-2023-03-07-at-22}
\end{center}
\begin{center}
	\textit{Illustration: Behaviour of path traced light in $\mathbb{R}^3$ that depicts $\vec{b}$ as a sphere and set $A$ in red as a two-dimensional subspace. When a subset of the sphere is an element of the subspace.}
	\label{fig:screenshot-2023-03-07-at-21}
\end{center}

\subsubsection{Contradiction to The Duality of Projections and Shadows}
\textbar{Let us contrast this with an example in $\mathbb{R}^2$ that demonstrates this contradiction: }

\begin{center}
	\textit{Choose a direction vector $\vec{d}$ that is not equal the zero vector in $\mathbb{R}^2$.} \\
	\textit{This direction vector will span one-dimensional subspace set $B$.} $B = span\left\lbrace \vec{d} \right\rbrace $ \\
	\textit{Then, choose another vector $\vec{c}$ that is colinear to our direction vector.}
	$ \vec{c} = \left\lbrace k\vec{d}: k \neq 1\right\rbrace$ \\
	\textit{Consider an arbitrary direction vector: }
	$\vec{d} = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$ \\
	\textit{Consider scalar multiple of direction vector:}
	$k = 2$ 
	\textit{... Then,} $\vec{c} = 2\vec{d} = \begin{bmatrix} 2 \\ 2 \end{bmatrix}$ \\
	
	\textit{We may compute the result of projecting set $B$ onto $\vec{c}$ with the formula we derived for projections.}
	

		$\vectorproj[B]{\vec{c}} =\frac{\vec{d} \cdot \vec{c}}{\vec{d} \cdot \vec{d}} \vec{d} = 2\vec{d}  = \begin{bmatrix} 2 \\ 2 \end{bmatrix} = \vec{c}$

		$Q.E.D.$
\end{center}
\textbar{Mathematically, the projection exists in the arbitrary one-dimensional subspace, while our mental model of a projection being a shadow says the projection cannot exist. Therefore, exceptions exist to our mental model of a projection being a shadow.}
\subsection{A Non-Existent Projection onto an Arbitrary Subspace}
\textbar{In section 2.1, we proposed we could construct a projection that did not exist. The assertion predicates the notion that if a set contained no vectors, there would be nothing for another given vector, which is not in the set, to project itself onto the set. Thus we need a mathematical object that relates to no elements in a set. A set with no elements is called an empty set $\emptyset$.}

\begin{center}


	\begin{tikzpicture}
		
		[x={(1cm,0.4cm)}, y={(8mm, -3mm)}, z={(0cm,1cm)}, line cap=round, line join=round]
		%Coordinates
		%Vectors Parallel to Plane
		%Beginning of Axis
		\coordinate (O) at (0,0);
		%Random Point
		%%	\node[outer sep = 1pt, inner sep = 1pt] (P) at (2.5,1,5.5) {};
		
		%Axis 	
		\draw[-latex] (-3,0,0) -- (3,0,0) node[above] {$x$};
		\draw[-latex] (0,-3,0) -- (0,3,0) node[pos = 1.05] {$y$};
		%%	\draw[draw=black, fill=black] (O) circle (1pt) node[below] {${O}$};
		
		%Vectors
		%\draw[-, thick, red] (-3,-1) -- node[pos = 1.05] {$A$} (3,1);
		%\draw[->, thick, blue] (0,0) -- node[below] {$\vec{c}$} (5,1);
		%\draw[->, thick, blue] (0,0) -- node[pos = 1.15] {$\vec{b}$} (1,1);
		
		%	%Random Point
		%	\draw[-latex, thick] (O) -- (P) node[pos=0.45, shift={(0.1,0.3)}] {$\vb{r}$};
		%	\draw[draw=black, fill=black] (P) circle (1pt) node[above right] {$\mathrm{P}$};
		
	\end{tikzpicture} 
	
\end{center}
\begin{center}
\textit{$\emptyset$ in $\mathbb{R}^2$}
\end{center}


\end{document}
